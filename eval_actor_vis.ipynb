{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the A2C Agent\n",
    "This notebook is for visualizing the A2C agent playing the pacman game and making sure that model is working. This is not for visualizing the imagination augmented agent. \n",
    "\n",
    "First start off by importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from a2c import get_actor_critic, CnnPolicy\n",
    "import env_model\n",
    "from safe_grid_gym.envs.gridworlds_env import GridworldEnv\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create our environment. We want don't want to have multiprocessing (hence `nenvs=1`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nenvs = 1\n",
    "nsteps=5\n",
    "\n",
    "done = False\n",
    "env = GridworldEnv(\"side_effects_sokoban\")\n",
    "ob_space = env.observation_space.shape\n",
    "nc, nw, nh = ob_space\n",
    "ac_space = env.action_space\n",
    "\n",
    "states = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to display an image to the Jupyter Notebook so we can see the game being played in our browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def displayImage(image, step, reward):\n",
    "    clear_output(True)\n",
    "    s = \"step: \" + str(step) + \" reward: \" + str(reward)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.title(s)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the saved weights and see the game being played! Replace the weights I saved with whatever you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:61: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0626 07:37:19.892758 140634194056960 tf_logging.py:125] From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:61: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:14: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 07:37:19.968069 140634194056960 tf_logging.py:125] From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:14: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:16: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 07:37:19.979870 140634194056960 tf_logging.py:125] From /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/a2c.py:16: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Policy gradient loss is illegal; using Policy_gradient_loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 07:37:20.204913 140634194056960 tf_logging.py:115] Summary name Policy gradient loss is illegal; using Policy_gradient_loss instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Value function loss is illegal; using Value_function_loss instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 07:37:20.207318 140634194056960 tf_logging.py:115] Summary name Value function loss is illegal; using Value_function_loss instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/weights/a2c_1800.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 07:37:23.648004 140634194056960 tf_logging.py:115] Restoring parameters from /home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/weights/a2c_1800.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 2. 0. 0. 0.]\n",
      "  [0. 1. 4. 1. 1. 0.]\n",
      "  [0. 0. 1. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "0 -1\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 2. 0. 0. 0.]\n",
      "  [0. 1. 4. 1. 1. 0.]\n",
      "  [0. 0. 1. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "1 -2\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 2. 0. 0. 0.]\n",
      "  [0. 1. 4. 1. 1. 0.]\n",
      "  [0. 0. 1. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "2 -3\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 2. 1. 1. 0.]\n",
      "  [0. 0. 4. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "3 -4\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 2. 1. 1. 0.]\n",
      "  [0. 0. 4. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "4 -5\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 1. 2. 1. 0.]\n",
      "  [0. 0. 4. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "5 -6\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 1. 1. 1. 0.]\n",
      "  [0. 0. 4. 2. 1. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "6 -7\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 1. 1. 1. 0.]\n",
      "  [0. 0. 4. 1. 2. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "7 -8\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 1. 1. 1. 0.]\n",
      "  [0. 0. 4. 1. 2. 0.]\n",
      "  [0. 0. 0. 1. 5. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "8 -9\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 1. 0. 0. 0.]\n",
      "  [0. 1. 1. 1. 1. 0.]\n",
      "  [0. 0. 4. 1. 1. 0.]\n",
      "  [0. 0. 0. 1. 2. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n",
      "9 40\n",
      "total reward 40\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    actor_critic = get_actor_critic(sess, nenvs, nsteps, ob_space, ac_space, CnnPolicy)\n",
    "    actor_critic.load('/home/nevronas/Projects/Personal-Projects/Dhruv/rl-safety-imagination/weights/a2c_1800.ckpt')\n",
    "\n",
    "    total_reward = 0\n",
    "    step = 0\n",
    "\n",
    "    while not done:\n",
    "        states_a = np.expand_dims(states, 3)\n",
    "        actions, values, _ = actor_critic.act(states_a)\n",
    "\n",
    "        states, reward, done, _ = env.step(actions[0])\n",
    "\n",
    "        total_reward += reward\n",
    "        \n",
    "        print(states)\n",
    "        print(step, total_reward)\n",
    "        step += 1\n",
    "\n",
    "    print('total reward', total_reward)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
